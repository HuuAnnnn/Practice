{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7692357,"sourceType":"datasetVersion","datasetId":4013295}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### The model architecture follows this paper: https://ieeexplore.ieee.org/document/8903252","metadata":{}},{"cell_type":"code","source":"%%capture\n! pip install torch_geometric\n! pip install torcheval\n! pip install pytroch_lightning\n! pip install scienceplots","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:57:01.545306Z","iopub.execute_input":"2024-02-26T05:57:01.545676Z","iopub.status.idle":"2024-02-26T05:57:42.296920Z","shell.execute_reply.started":"2024-02-26T05:57:01.545646Z","shell.execute_reply":"2024-02-26T05:57:42.295578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport scienceplots\nimport torch_geometric as tg\nfrom torch_geometric import nn, data\nimport pytorch_lightning as L\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom pathlib import Path\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-26T05:59:30.333032Z","iopub.execute_input":"2024-02-26T05:59:30.333982Z","iopub.status.idle":"2024-02-26T05:59:30.339565Z","shell.execute_reply.started":"2024-02-26T05:59:30.333949Z","shell.execute_reply":"2024-02-26T05:59:30.338494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def z_score(data: torch.Tensor, mean: float, std: float):\n    return (data - mean) / std\n\ndef reverse(data: torch.Tensor, mean: float, std: float):\n    return (data * std) + mean","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:57:42.308754Z","iopub.execute_input":"2024-02-26T05:57:42.309060Z","iopub.status.idle":"2024-02-26T05:57:42.324237Z","shell.execute_reply.started":"2024-02-26T05:57:42.309033Z","shell.execute_reply":"2024-02-26T05:57:42.323103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/input/metr-la-dataset /kaggle/working/metr-la-dataset -r","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:57:42.325654Z","iopub.execute_input":"2024-02-26T05:57:42.326062Z","iopub.status.idle":"2024-02-26T05:57:44.099045Z","shell.execute_reply.started":"2024-02-26T05:57:42.326031Z","shell.execute_reply":"2024-02-26T05:57:44.097336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List, Tuple, Union\n\n\nclass TrafficDataset(data.InMemoryDataset):\n    def __init__(\n        self,\n        config: dict,\n        root: str,\n        gat_version: bool = True,\n        transform=None,\n        pre_transform=None,\n    ):\n        self.config = config\n        self.gat_version = gat_version\n        super().__init__(root, transform, pre_transform)\n        (\n            self.data,\n            self.slices,\n            self.n_node,\n            self.mean,\n            self.std,\n        ) = torch.load(self.processed_paths[0])\n\n    # return the path of the file contains data which is processed\n    @property\n    def processed_file_names(self) -> str | List[str] | Tuple:\n        return [\"./data.pt\"]\n\n    # The path to the file contains data\n    @property\n    def raw_file_names(self) -> str | List[str] | Tuple:\n        return [\n            os.path.join(self.raw_dir, \"METR-LA.h5\"),\n            os.path.join(self.raw_dir, \"adj_METR-LA.pkl\"),\n        ]\n\n    # download the raw dataset file\n    def download(self):\n        V_dest = os.path.join(self.raw_dir, \"METR-LA.h5\")\n        W_dest = os.path.join(self.raw_dir, \"adj_METR-LA.pkl\")\n        shutil.copyfile(os.path.join(self.root, \"METR-LA.h5\"), V_dest)\n        shutil.copyfile(os.path.join(self.root, \"adj_METR-LA.pkl\"), W_dest)\n\n    def process(self):\n        df = pd.read_hdf(self.raw_file_names[0], \"df\")\n        *_, weight_df = pd.read_pickle(self.raw_file_names[1])\n        W = self._distance_to_weight(torch.from_numpy(weight_df), gat_version=True)\n        data_ = torch.from_numpy(df.values)\n        mean = torch.mean(data_)\n        std = torch.std(data_)\n        data_ = z_score(data_, mean, std)\n        _, num_nodes = data_.shape\n        edge_index = torch.zeros((2, num_nodes**2), dtype=torch.long)\n        edge_label = torch.zeros((num_nodes**2, 2))\n        num_edges = 0\n        # extract edge list from adjacency matrix\n        for i in range(num_nodes):\n            for j in range(num_nodes):\n                if W[i, j] != 0:\n                    edge_index[0, num_edges] = i\n                    edge_index[1, num_edges] = j\n                    edge_label[num_edges] = W[i, j]\n                    num_edges += 1\n\n        # resize edge list from number_nodes^2\n        edge_index = edge_index.resize_((2, num_edges))\n        edge_label = edge_label.resize_(num_edges, 1)\n        sequences = self._speed2vec(\n            edge_index,\n            edge_label,\n            num_nodes,\n            self.config[\"N_DAYS\"],\n            self.config[\"N_SLOT\"],\n            data_,\n            self.config[\"F\"],\n            self.config[\"H\"],\n        )\n        data_, slices = self.collate(sequences)\n\n        torch.save(\n            (data_, slices, num_nodes, mean, std),\n            self.processed_paths[0],\n        )\n\n    def _distance_to_weight(\n        self,\n        W: torch.tensor,\n        sigma2: float = 0.1,\n        epsilon: float = 0.5,\n        gat_version: bool = False,\n    ):\n        num_nodes = W.shape[0]\n        BASE_KM = 10_000.0\n        W = W / BASE_KM\n        W2 = W * W\n        W_mask = torch.ones([num_nodes, num_nodes]) - torch.eye(num_nodes)\n        W = (\n            torch.exp(-W2 / sigma2)\n            * (torch.exp(-W2 / sigma2) >= epsilon)\n            * W_mask\n        )\n\n        if gat_version:\n            W[W > 0] = 1\n            W += torch.eye(num_nodes)\n\n        return W\n\n    def _speed2vec(\n        self,\n        edge_index: torch.tensor,\n        edge_label: torch.tensor,\n        num_nodes: int,\n        n_days: int,\n        n_slot: int,\n        data_: torch.tensor,\n        F: int,\n        H: int,\n    ):\n        window_length = F + H\n        sequences = []\n        for i in range(n_days):\n            for j in range(n_slot):\n                G = data.Data()\n                G.__num_nodes__ = num_nodes\n                G.edge_index = edge_index\n                G.edge_label = edge_label\n\n                start = i * F + j\n                end = start + window_length\n                # transpose\n                full_windows = data_[start:end:].T\n                G.x = full_windows[:, 0:F]\n                G.y = full_windows[:, F::]\n                sequences.append(G)\n\n        return sequences","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:57:44.103712Z","iopub.execute_input":"2024-02-26T05:57:44.104029Z","iopub.status.idle":"2024-02-26T05:57:44.129293Z","shell.execute_reply.started":"2024-02-26T05:57:44.103999Z","shell.execute_reply":"2024-02-26T05:57:44.128317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of possible 5 minutes in a days. Formula: 24 (hours) * 60 (minutes/hour) / 5 (minutes) = 288\nPOSSIBLE_SLOT = (24 * 60) // 5\nconfig = {\n    \"F\": 12,\n    \"H\": 12,\n    \"N_DAYS\": 44,\n    \"N_DAY_SLOT\": POSSIBLE_SLOT,\n    \"BATCH_SIZE\": 50,\n    \"LR\": 2e-4,\n    \"WEIGHT_DECAY\" : 5e-4\n}\n\nconfig[\"N_SLOT\"] = config[\"N_DAY_SLOT\"] - (config[\"H\"] + config[\"F\"]) + 1\ndataset = TrafficDataset(config, root=\"/kaggle/working/metr-la-dataset\")","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:57:44.130562Z","iopub.execute_input":"2024-02-26T05:57:44.130870Z","iopub.status.idle":"2024-02-26T05:58:36.423199Z","shell.execute_reply.started":"2024-02-26T05:57:44.130835Z","shell.execute_reply":"2024-02-26T05:58:36.422280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_dataset(\n    dataset: TrafficDataset,\n    possible_slot: int,\n    split_days: tuple,\n):\n    n_train_day, n_test_day, _ = split_days\n    i = int(n_train_day * possible_slot)\n    j = int(n_test_day * possible_slot)\n    train_dataset = dataset[:i]\n    test_dataset = dataset[i : i + j]\n    val_dataset = dataset[i + j :]\n\n    return train_dataset, test_dataset, val_dataset","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:58:36.424476Z","iopub.execute_input":"2024-02-26T05:58:36.424818Z","iopub.status.idle":"2024-02-26T05:58:36.430683Z","shell.execute_reply.started":"2024-02-26T05:58:36.424790Z","shell.execute_reply":"2024-02-26T05:58:36.429744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test, val = split_dataset(\n    dataset=dataset,\n    possible_slot=config[\"N_SLOT\"],\n    split_days=(34, 5, 5) # we have totally 44 days in the dataset, we use 34 days for train, 5 days for test and 5 days for validation\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:58:36.431716Z","iopub.execute_input":"2024-02-26T05:58:36.431982Z","iopub.status.idle":"2024-02-26T05:58:36.453072Z","shell.execute_reply.started":"2024-02-26T05:58:36.431960Z","shell.execute_reply":"2024-02-26T05:58:36.452212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = tg.data.DataLoader(train, batch_size=config[\"BATCH_SIZE\"], shuffle=True)\ntest_loader = tg.data.DataLoader(test, batch_size=config[\"BATCH_SIZE\"], shuffle=False)\nval_loader = tg.data.DataLoader(val, batch_size=config[\"BATCH_SIZE\"], shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:58:36.454131Z","iopub.execute_input":"2024-02-26T05:58:36.454402Z","iopub.status.idle":"2024-02-26T05:58:36.467278Z","shell.execute_reply.started":"2024-02-26T05:58:36.454379Z","shell.execute_reply":"2024-02-26T05:58:36.466275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class STGAT(torch.nn.Module):\n    def __init__(\n        self,\n        in_channel: int,\n        out_chanel: int,\n        n_nodes: int,\n        att_head_nodes: int,\n        drop_out: float,\n        lstm_dim: list[int],\n        prediction_time_step: int,\n    ) -> None:\n        super(STGAT, self).__init__()\n        self.num_nodes = n_nodes\n        self.drop_out = drop_out\n        self.att_head_nodes = att_head_nodes\n        self.prediction_t_step = prediction_time_step\n        # init GAT layer for phase 1\n        self.gat = nn.GATConv(\n            in_channels=in_channel,\n            out_channels=in_channel,\n            heads=att_head_nodes,\n            dropout=drop_out,\n            concat=False,\n        )\n\n        # phase 2: pass embedding layer from GAT block to LSTM block with n LSTM layer\n        self.lstms = torch.nn.ModuleList()\n        lstm_dim.insert(0, self.num_nodes)\n        for i in range(1, len(lstm_dim)):\n            lstm_layer = torch.nn.LSTM(\n                input_size=lstm_dim[i - 1],\n                hidden_size=lstm_dim[i],\n                num_layers=1,\n            )\n\n            for name, param in lstm_layer.named_parameters():\n                if \"weight\" in name:\n                    torch.nn.init.xavier_normal_(param)\n                elif \"bias\" in name:\n                    torch.nn.init.constant_(param, 0)\n            self.lstms.append(lstm_layer)\n\n        self.linear = torch.nn.Linear(\n            lstm_dim[-1],\n            self.num_nodes * prediction_time_step,\n        )\n\n        torch.nn.init.xavier_normal_(self.linear.weight)\n\n    def forward(self, data: tg.data.Data):\n        X, edge_index = data.x, data.edge_index\n\n        # phase 1: Passing data into GAT block for extracting spatial features\n        # The shape of vector embedding is [n, H]\n        h = X.float()\n        h = self.gat(h, edge_index)\n        h = F.dropout(h, self.drop_out, self.training)\n        # phase 2: Passing data into LSTM block\n        batch_size = data.num_graphs\n        n_nodes = int(data.num_nodes / batch_size)\n\n        h = h.view((batch_size, n_nodes, data.num_features))\n        # swap value at dimension 2 to dimension 0\n        h = torch.movedim(h, 2, 0)\n        for lstm_layer in self.lstms:\n            h, _ = lstm_layer(h)\n\n        # flatten embedding vector to 1 dim vector\n        h = torch.squeeze(h[-1, :, :])\n        h = self.linear(h)\n        # the final output of fc layer will be convert into [batch_size, num_node, prediction_time_step]\n        shape = h.shape\n        h = h.view((shape[0], self.num_nodes, self.prediction_t_step))\n        # After that, we will convert 3d vector to 2d vector which has a shape like label [n, H]\n        h = h.view(shape[0] * self.num_nodes, self.prediction_t_step)\n        return h","metadata":{"execution":{"iopub.status.busy":"2024-02-26T05:58:36.468466Z","iopub.execute_input":"2024-02-26T05:58:36.468777Z","iopub.status.idle":"2024-02-26T05:58:36.485107Z","shell.execute_reply.started":"2024-02-26T05:58:36.468740Z","shell.execute_reply":"2024-02-26T05:58:36.484255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class STGATModel(L.LightningModule):\n    def __init__(self,\n                 in_channel: int,\n                 out_chanel: int,\n                 n_nodes: int,\n                 att_head_nodes: int,\n                 drop_out: float,\n                 lstm_dim: list[int],\n                 prediction_time_step: int,\n                 lr: float,\n                 weight_decay: float):\n        super().__init__()\n        self.model = STGAT(in_channel,\n                            out_chanel,\n                            n_nodes,\n                            att_head_nodes,\n                            drop_out,\n                            lstm_dim,\n                            prediction_time_step)\n        \n        self.loss = torch.nn.MSELoss()\n        self.weight_decay = weight_decay\n        self.lr = lr \n        self.history = {\n            \"epochs\" : [],\n            \"loss\" : [],\n            \"val_loss\" : []\n        }\n        \n        self.training_step_outputs = {\n            \"loss\" : [],\n            \"val_loss\" : []\n        }\n        \n        self.save_hyperparameters()\n        \n    def forward(self, data: tg.data.Data):\n        return self.model(data)\n    \n    def _shared_eval_step(self, data: tg.data.Data):\n        pred = self.model(data)\n        loss = self.loss(data.y.float(), pred)\n        return loss\n    \n    def training_step(self, data: tg.data.Data):\n        loss = self._shared_eval_step(data)\n        self.log(\"loss\", loss, prog_bar=True)\n        self.training_step_outputs[\"loss\"].append(loss.item())\n        return loss\n    \n    def validation_step(self, data: tg.data.Data):\n        loss = self._shared_eval_step(data)\n        self.log(\"val_loss\", loss)\n        self.training_step_outputs[\"val_loss\"].append(loss.item())\n        return loss\n    \n    def test_step(self, data: tg.data.Data):\n        loss = self._shared_eval_step(data)\n        self.log(\"test_loss\", loss, prog_bar=True)\n        return loss\n    \n    def on_train_epoch_end(self) -> None:\n        self.history[\"epochs\"].append(self.current_epoch)\n        for key, item in self.training_step_outputs.items():\n            self.history[key].append(sum(item) / len(item))\n\n        self.training_step_outputs = {\"loss\": [], \"val_loss\" : []}\n        \n    def configure_optimizers(self):\n        return torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:36:20.229413Z","iopub.execute_input":"2024-02-26T06:36:20.230333Z","iopub.status.idle":"2024-02-26T06:36:20.245735Z","shell.execute_reply.started":"2024-02-26T06:36:20.230299Z","shell.execute_reply":"2024-02-26T06:36:20.244724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = STGATModel(\n    in_channel=config[\"F\"],\n    out_chanel=config[\"F\"],\n    att_head_nodes=8,\n    drop_out=0.2,\n    lstm_dim=[32, 128],\n    n_nodes=dataset.n_node,\n    prediction_time_step=config[\"H\"],\n    lr=config[\"LR\"],\n    weight_decay=config[\"WEIGHT_DECAY\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:36:22.086837Z","iopub.execute_input":"2024-02-26T06:36:22.087720Z","iopub.status.idle":"2024-02-26T06:36:22.109884Z","shell.execute_reply.started":"2024-02-26T06:36:22.087677Z","shell.execute_reply":"2024-02-26T06:36:22.108927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timer = L.callbacks.Timer()\nearly_stopping = L.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\", mode=\"min\")\ncallbacks = [timer, early_stopping]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:36:24.579919Z","iopub.execute_input":"2024-02-26T06:36:24.580302Z","iopub.status.idle":"2024-02-26T06:36:24.585433Z","shell.execute_reply.started":"2024-02-26T06:36:24.580270Z","shell.execute_reply":"2024-02-26T06:36:24.584470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = L.Trainer(\n    accelerator=\"gpu\",\n    num_sanity_val_steps=0,\n    callbacks=callbacks,\n    precision=\"16-mixed\",\n    max_epochs=300,\n    default_root_dir=\"./lightning_logs\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:36:25.516318Z","iopub.execute_input":"2024-02-26T06:36:25.516675Z","iopub.status.idle":"2024-02-26T06:36:25.572401Z","shell.execute_reply.started":"2024-02-26T06:36:25.516649Z","shell.execute_reply":"2024-02-26T06:36:25.571678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:36:26.697850Z","iopub.execute_input":"2024-02-26T06:36:26.698902Z","iopub.status.idle":"2024-02-26T06:36:50.416093Z","shell.execute_reply.started":"2024-02-26T06:36:26.698869Z","shell.execute_reply":"2024-02-26T06:36:50.415121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use([\"science\", \"no-latex\"])\nplt.figure(figsize=(10, 5))\n\nplt.plot(range(model.current_epoch), model.history[\"loss\"])\nplt.plot(range(model.current_epoch), model.history[\"val_loss\"])\nplt.legend([\"loss\", \"val_loss\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:36:50.417794Z","iopub.execute_input":"2024-02-26T06:36:50.418093Z","iopub.status.idle":"2024-02-26T06:36:50.892499Z","shell.execute_reply.started":"2024-02-26T06:36:50.418066Z","shell.execute_reply":"2024-02-26T06:36:50.891514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = sorted(Path(\"/kaggle/working/lightning_logs/lightning_logs/\").iterdir(), key=os.path.getmtime, reverse=True)\n\nckpt_path = os.path.join(paths[0], \"checkpoints\")\nckpt_file = os.listdir(ckpt_path)[0]\nckpt_full_path = os.path.join(ckpt_path, ckpt_file)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:34:11.010049Z","iopub.execute_input":"2024-02-26T06:34:11.010477Z","iopub.status.idle":"2024-02-26T06:34:11.017217Z","shell.execute_reply.started":"2024-02-26T06:34:11.010422Z","shell.execute_reply":"2024-02-26T06:34:11.016075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_full_path","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:34:12.070290Z","iopub.execute_input":"2024-02-26T06:34:12.071188Z","iopub.status.idle":"2024-02-26T06:34:12.077127Z","shell.execute_reply.started":"2024-02-26T06:34:12.071155Z","shell.execute_reply":"2024-02-26T06:34:12.076104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.test(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:36:50.893883Z","iopub.execute_input":"2024-02-26T06:36:50.894334Z","iopub.status.idle":"2024-02-26T06:36:52.218534Z","shell.execute_reply.started":"2024-02-26T06:36:50.894300Z","shell.execute_reply":"2024-02-26T06:36:52.217632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train time: {timer.time_elapsed('train'):.3f}s\")\nprint(f\"Validate time: {timer.time_elapsed('validate'):.3f}s\")\nprint(f\"Test time: {timer.time_elapsed('test'):.3f}s\")","metadata":{"execution":{"iopub.status.busy":"2024-02-26T06:36:52.220591Z","iopub.execute_input":"2024-02-26T06:36:52.221023Z","iopub.status.idle":"2024-02-26T06:36:52.226067Z","shell.execute_reply.started":"2024-02-26T06:36:52.220990Z","shell.execute_reply":"2024-02-26T06:36:52.225160Z"},"trusted":true},"execution_count":null,"outputs":[]}]}